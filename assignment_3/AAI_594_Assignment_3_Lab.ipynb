{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAI 594 — Assignment 3\n",
    "\n",
    "## Building Agent Tools\n",
    "\n",
    "**In this lab you will:**\n",
    "- **Required (Sections 1–5):** Create **Unity Catalog function tools** — one SQL function and one Python function — and test them.\n",
    "- **Required (Section 6):** Set up **Vector Search** on the UltraFeedback dataset so an agent can find similar instructions by meaning.\n",
    "- **Required (Section 7):** Configure an **external MCP server** (You.com web search) in Cursor so your agent can access live web information.\n",
    "- **Optional, strongly encouraged (Section 8):** Create an **Agent Skill** (`SKILL.md`) that documents the tools you built.\n",
    "\n",
    "### The big picture\n",
    "\n",
    "Over Weeks 3–5 you are building an **UltraFeedback Expert** agent — an AI assistant that helps users explore and understand LLM preference data. This week you create the **tools**; next week you wire them into a working agent; in Week 5 you evaluate how well it performs.\n",
    "\n",
    "| Week | What you do | Deliverable |\n",
    "|------|------------|-------------|\n",
    "| 3 (this week) | Build tools: UC functions, Vector Search, MCP | Tested tools + MCP config |\n",
    "| 4 | Wire tools into an agent; register a prompt; compare LLMs | Working agent |\n",
    "| 5 | Evaluate the agent with judges and an eval dataset | Evaluation report |\n",
    "\n",
    "**Readings this week:**\n",
    "- [Practical Guide for Agentic AI Workflows](https://arxiv.org/pdf/2512.08769)\n",
    "- [MCP Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\n",
    "\n",
    "**Key docs:**\n",
    "- [Create AI agent tools with UC functions](https://docs.databricks.com/aws/en/generative-ai/agent-framework/create-custom-tool)\n",
    "- [Vector Search: Create endpoints and indexes](https://docs.databricks.com/aws/en/vector-search/create-vector-search)\n",
    "- [You.com MCP Server](https://docs.you.com/developer-resources/mcp-server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Why agents need tools *(Required)*\n",
    "\n",
    "An LLM on its own can only generate text. **Tools** give agents the ability to *act* — query databases, search the web, look up facts, run computations. In this assignment you'll create three kinds of tools:\n",
    "\n",
    "| Tool type | What it does | Example |\n",
    "|-----------|-------------|--------|\n",
    "| **UC SQL function** | Deterministic lookup against structured data | \"How many rows come from `evol_instruct`?\" |\n",
    "| **UC Python function** | Custom computation or text processing | \"Analyze the complexity of this instruction\" |\n",
    "| **Vector Search** | Semantic similarity search over text | \"Find instructions similar to *Explain quantum tunneling*\" |\n",
    "| **External MCP** | Access external services (web search, APIs) | \"Search the web for recent LLM benchmarks\" |\n",
    "\n",
    "Each tool is registered in a place the agent can discover it — Unity Catalog for functions and Vector Search, MCP for external services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Install dependencies *(Required)*\n",
    "\n",
    "We need two packages:\n",
    "- `unitycatalog-ai[databricks]` — the Unity Catalog AI client for creating and testing UC functions as agent tools.\n",
    "- `databricks-vectorsearch` — the Vector Search SDK for creating endpoints and indexes.\n",
    "\n",
    "**Docs:** [Unity Catalog AI](https://docs.unitycatalog.io/ai/) · [Vector Search SDK](https://api-docs.databricks.com/python/vector-search/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the UC AI client (for creating/testing UC functions as tools)\n",
    "# and the Vector Search SDK (for creating endpoints and indexes)\n",
    "%pip install unitycatalog-ai[databricks] databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Verify your data *(Required)*\n",
    "\n",
    "Confirm the UltraFeedback table from Assignment 1 is still available. If you get an error, re-run Assignment 1 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: confirm the table exists, show schema and row count\n",
    "df = spark.table(\"main.default.assignment_file\")\n",
    "print(f\"Row count: {df.count():,}\")\n",
    "print(f\"Columns:  {df.columns}\")\n",
    "df.printSchema()\n",
    "display(df.limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create Unity Catalog function tools *(Required)*\n",
    "\n",
    "Unity Catalog functions are UDFs registered in `catalog.schema.function_name`. When an agent needs a tool, it calls the function by name. Two patterns are common:\n",
    "\n",
    "1. **SQL functions** — best for deterministic lookups against tables (e.g., counts, filters, joins).\n",
    "2. **Python functions** — best for custom logic, text processing, or computations that don't map cleanly to SQL.\n",
    "\n",
    "You'll create one of each, then build your own.\n",
    "\n",
    "**Docs:** [Create AI agent tools with UC functions](https://docs.databricks.com/aws/en/generative-ai/agent-framework/create-custom-tool) · [CREATE FUNCTION syntax](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-create-sql-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 SQL function: `lookup_source_info`\n",
    "\n",
    "This function takes a source name (like `evol_instruct` or `sharegpt`) and returns the row count plus a sample instruction. An agent can call this to understand what kind of data each source contains.\n",
    "\n",
    "**Key points:**\n",
    "- The `COMMENT` on the function and its parameters helps the agent understand *when* and *how* to use the tool. Write clear, descriptive comments.\n",
    "- The function returns a `STRING` — this is the simplest return type for agent tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Create a SQL UC function that looks up source information.\n",
    "-- The COMMENT fields are critical: they tell the agent what this tool does.\n",
    "CREATE OR REPLACE FUNCTION main.default.lookup_source_info(\n",
    "  source_name STRING COMMENT 'Name of the data source to look up (e.g., evol_instruct, sharegpt, ultrachat, flan_v2).'\n",
    ")\n",
    "RETURNS STRING\n",
    "COMMENT 'Returns the row count and a sample instruction for a given source in the UltraFeedback dataset. Use this to understand what kind of data each source contains and how much is available.'\n",
    "RETURN\n",
    "  SELECT CONCAT(\n",
    "    'Source: ', source_name,\n",
    "    ' | Row count: ', CAST(COUNT(*) AS STRING),\n",
    "    ' | Sample instruction: ', COALESCE(FIRST(instruction), 'N/A')\n",
    "  )\n",
    "  FROM main.default.assignment_file\n",
    "  WHERE source = source_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Test the function with a known source name.\n",
    "-- Try different sources: evol_instruct, sharegpt, ultrachat, flan_v2, false_qa, etc.\n",
    "SELECT main.default.lookup_source_info('evol_instruct') AS result;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Python function: `analyze_instruction`\n",
    "\n",
    "This function takes an instruction text and returns complexity metrics (word count, sentence count, estimated complexity level). An agent could use this to assess how complex a prompt is before deciding how to handle it.\n",
    "\n",
    "**Key points:**\n",
    "- Python UC functions must have **type hints** on all arguments and the return value.\n",
    "- **Imports go inside the function body** — they won't be resolved otherwise.\n",
    "- Use [Google-style docstrings](https://google.github.io/styleguide/pyguide.html#383-functions-and-methods) so the agent can parse the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "# Initialize the Databricks Function Client\n",
    "uc_client = DatabricksFunctionClient()\n",
    "\n",
    "# Define the Python function with type hints and a clear docstring.\n",
    "# NOTE: all imports must be INSIDE the function body.\n",
    "def analyze_instruction(instruction: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the complexity and characteristics of an instruction prompt.\n",
    "\n",
    "    Returns word count, sentence count, average word length, estimated\n",
    "    complexity level (low/medium/high), and whether the text is a question.\n",
    "    Use this to assess instruction difficulty before generating a response.\n",
    "\n",
    "    Args:\n",
    "        instruction: The instruction or prompt text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        A JSON string with analysis metrics.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import re\n",
    "\n",
    "    words = instruction.split()\n",
    "    word_count = len(words)\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]+', instruction) if s.strip()]\n",
    "    sentence_count = len(sentences)\n",
    "    avg_word_length = round(sum(len(w) for w in words) / max(word_count, 1), 1)\n",
    "    is_question = instruction.strip().endswith('?')\n",
    "\n",
    "    if word_count > 50 or sentence_count > 3:\n",
    "        complexity = \"high\"\n",
    "    elif word_count > 20:\n",
    "        complexity = \"medium\"\n",
    "    else:\n",
    "        complexity = \"low\"\n",
    "\n",
    "    return json.dumps({\n",
    "        \"word_count\": word_count,\n",
    "        \"sentence_count\": sentence_count,\n",
    "        \"avg_word_length\": avg_word_length,\n",
    "        \"complexity\": complexity,\n",
    "        \"is_question\": is_question\n",
    "    })\n",
    "\n",
    "# Register the function in Unity Catalog (main.default schema)\n",
    "function_info = uc_client.create_python_function(\n",
    "    func=analyze_instruction,\n",
    "    catalog=\"main\",\n",
    "    schema=\"default\",\n",
    "    replace=True  # overwrite if it already exists\n",
    ")\n",
    "print(f\"Registered: {function_info.full_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Python function through the UC client\n",
    "result = uc_client.execute_function(\n",
    "    function_name=\"main.default.analyze_instruction\",\n",
    "    parameters={\"instruction\": \"Explain the process of photosynthesis in detail, including the light-dependent and light-independent reactions.\"}\n",
    ")\n",
    "print(result.value)\n",
    "\n",
    "# Try a simpler instruction for comparison\n",
    "result2 = uc_client.execute_function(\n",
    "    function_name=\"main.default.analyze_instruction\",\n",
    "    parameters={\"instruction\": \"What is 2 + 2?\"}\n",
    ")\n",
    "print(result2.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Your turn: create a function *(Required)*\n",
    "\n",
    "Create **one additional UC function** (SQL or Python) that would be useful for the UltraFeedback Expert agent. Some ideas:\n",
    "\n",
    "| Idea | Type | What it does |\n",
    "|------|------|--------------|\n",
    "| `count_model_appearances` | SQL | Count how often a model appears as chosen vs. rejected |\n",
    "| `get_sample_pairs` | SQL | Return N example chosen/rejected pairs for a given source |\n",
    "| `format_comparison` | Python | Take a chosen and rejected response and format them side-by-side |\n",
    "| `extract_keywords` | Python | Pull key terms from an instruction for categorization |\n",
    "\n",
    "Make sure your function has:\n",
    "- A clear `COMMENT` (SQL) or docstring (Python) explaining what it does and when to use it\n",
    "- Type hints (Python) or typed parameters (SQL)\n",
    "- A test cell showing it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE YOUR FUNCTION HERE\n",
    "# Use either %%sql for a SQL function or Python with uc_client.create_python_function()\n",
    "# Then add a test cell below to verify it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST YOUR FUNCTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. List your registered tools\n",
    "\n",
    "Before moving on, verify all your UC functions are registered. The cell below lists functions in `main.default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- List all functions you've created in main.default\n",
    "SHOW USER FUNCTIONS IN main.default;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Vector Search *(Required)*\n",
    "\n",
    "Vector Search lets an agent find **semantically similar** text — not just exact keyword matches. For the UltraFeedback Expert, this means an agent can find instructions similar to a user's question, even if the wording is different.\n",
    "\n",
    "**How it works:**\n",
    "1. You create a **Vector Search endpoint** (the compute that serves queries).\n",
    "2. You create a **Delta Sync Index** on a source table — Databricks automatically computes embeddings and keeps the index in sync.\n",
    "3. The agent queries the index with natural language and gets back similar rows.\n",
    "\n",
    "**Free Edition limits:** One Vector Search endpoint, one unit. No Direct Vector Access. This is enough for our purposes.\n",
    "\n",
    "**Docs:** [Create Vector Search endpoints and indexes](https://docs.databricks.com/aws/en/vector-search/create-vector-search) · [Vector Search SDK reference](https://api-docs.databricks.com/python/vector-search/databricks.vector_search.html)\n",
    "\n",
    "> **Important:** Vector Search endpoints consume resources even when idle. You will **delete the endpoint at the end of this section**. You can recreate it in Assignment 4 when you build the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prepare a source table\n",
    "\n",
    "Vector Search requires:\n",
    "- A **primary key** column (unique identifier for each row).\n",
    "- A **text column** to embed (we'll use the `instruction` column).\n",
    "- **Change Data Feed** enabled on the Delta table (required for Delta Sync Index).\n",
    "\n",
    "We'll create a focused table with 1,000 unique instructions — this keeps indexing fast and stays within Free Edition quotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Create a focused table for Vector Search:\n",
    "# - Unique instructions only (deduplicated)\n",
    "# - Limited to 1,000 rows (keeps indexing fast on Free Edition)\n",
    "# - Includes an ID column for the primary key\n",
    "vs_source = (\n",
    "    spark.table(\"main.default.assignment_file\")\n",
    "    .select(\"source\", \"instruction\")\n",
    "    .dropDuplicates([\"instruction\"])\n",
    "    .limit(1000)\n",
    "    .withColumn(\"id\", monotonically_increasing_id())\n",
    ")\n",
    "\n",
    "# Write as a new Delta table with Change Data Feed enabled\n",
    "vs_source.write.format(\"delta\") \\\n",
    "    .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"main.default.ultrafeedback_vs_source\")\n",
    "\n",
    "# Verify\n",
    "print(f\"VS source table rows: {spark.table('main.default.ultrafeedback_vs_source').count()}\")\n",
    "display(spark.table(\"main.default.ultrafeedback_vs_source\").limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Create a Vector Search endpoint\n",
    "\n",
    "The endpoint is the compute resource that serves similarity queries. On Free Edition you get one endpoint with one unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Initialize the Vector Search client (auto-detects notebook credentials)\n",
    "vs_client = VectorSearchClient()\n",
    "\n",
    "VS_ENDPOINT_NAME = \"aai594_vs_endpoint\"\n",
    "\n",
    "# Create the endpoint (this may take 1-2 minutes)\n",
    "try:\n",
    "    vs_client.create_endpoint_and_wait(\n",
    "        name=VS_ENDPOINT_NAME,\n",
    "        endpoint_type=\"STANDARD\"\n",
    "    )\n",
    "    print(f\"Endpoint '{VS_ENDPOINT_NAME}' is ready.\")\n",
    "except Exception as e:\n",
    "    # If the endpoint already exists, that's fine\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"Endpoint '{VS_ENDPOINT_NAME}' already exists — reusing it.\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Create a Delta Sync Index\n",
    "\n",
    "The index tells Vector Search which table to embed and how. We use **managed embeddings** — Databricks automatically computes embeddings using a Foundation Model API endpoint (`databricks-gte-large-en`).\n",
    "\n",
    "- `pipeline_type=\"TRIGGERED\"` means the index syncs when you explicitly ask it to (not continuously). This saves resources.\n",
    "- `embedding_source_column=\"instruction\"` — the text column to embed.\n",
    "\n",
    "> **Note:** If `databricks-gte-large-en` is not available in your workspace, check which embedding endpoints are available under **Serving** in the left sidebar and substitute the endpoint name below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VS_INDEX_NAME = \"main.default.ultrafeedback_vs_index\"\n",
    "\n",
    "# Create a Delta Sync Index with managed embeddings\n",
    "try:\n",
    "    index = vs_client.create_delta_sync_index_and_wait(\n",
    "        endpoint_name=VS_ENDPOINT_NAME,\n",
    "        source_table_name=\"main.default.ultrafeedback_vs_source\",\n",
    "        index_name=VS_INDEX_NAME,\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"id\",\n",
    "        embedding_source_column=\"instruction\",\n",
    "        embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "    )\n",
    "    print(f\"Index '{VS_INDEX_NAME}' created and synced.\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"Index '{VS_INDEX_NAME}' already exists — reusing it.\")\n",
    "        index = vs_client.get_index(\n",
    "            endpoint_name=VS_ENDPOINT_NAME,\n",
    "            index_name=VS_INDEX_NAME\n",
    "        )\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the index status — it should show as ONLINE after syncing\n",
    "# If status is still PROVISIONING, wait a minute and re-run this cell.\n",
    "index.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Query the index\n",
    "\n",
    "Now test a similarity search. The query text is embedded automatically and compared against the indexed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search: find instructions related to a query\n",
    "results = index.similarity_search(\n",
    "    query_text=\"Explain how machine learning models are trained\",\n",
    "    columns=[\"id\", \"instruction\", \"source\"],\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for row in results.get(\"result\", {}).get(\"data_array\", []):\n",
    "    print(f\"Score: {row[-1]:.4f} | Source: {row[2]} | Instruction: {row[1][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own query — replace the text below\n",
    "results2 = index.similarity_search(\n",
    "    query_text=\"Write a Python function to sort a list\",\n",
    "    columns=[\"id\", \"instruction\", \"source\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "for row in results2.get(\"result\", {}).get(\"data_array\", []):\n",
    "    print(f\"Score: {row[-1]:.4f} | {row[1][:120]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Clean up — delete endpoint and index\n",
    "\n",
    "**This step is critical.** Vector Search endpoints consume resources even when idle. On Free Edition you only get one, and leaving it running counts against your daily quota.\n",
    "\n",
    "Delete the index first, then the endpoint. You'll recreate them in Assignment 4 when you build the full agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Delete the index\n",
    "try:\n",
    "    vs_client.delete_index(\n",
    "        endpoint_name=VS_ENDPOINT_NAME,\n",
    "        index_name=VS_INDEX_NAME\n",
    "    )\n",
    "    print(f\"Index '{VS_INDEX_NAME}' deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Index deletion note: {e}\")\n",
    "\n",
    "# Step 2: Delete the endpoint\n",
    "try:\n",
    "    vs_client.delete_endpoint(name=VS_ENDPOINT_NAME)\n",
    "    print(f\"Endpoint '{VS_ENDPOINT_NAME}' deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint deletion note: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify cleanup: this should return an empty list (or not include your endpoint)\n",
    "vs_client.list_endpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Configure an external MCP server *(Required)*\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an open standard that lets AI assistants connect to external tools and data sources. By adding an MCP server to Cursor, your agent gains access to live capabilities — in this case, **web search**.\n",
    "\n",
    "You'll configure the **You.com MCP server**, which provides:\n",
    "- `you-search` — web and news search with filtering\n",
    "- `you-contents` — extract content from URLs in markdown format\n",
    "\n",
    "This means your agent will be able to search the web for current information about LLMs, benchmarks, and research papers — something it can't do with just the UltraFeedback dataset.\n",
    "\n",
    "**Docs:** [You.com MCP Server](https://docs.you.com/developer-resources/mcp-server) · [MCP in Cursor](https://cursor.com/docs/context/mcp) · [MCP Architecture](https://modelcontextprotocol.io/docs/learn/architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Get a You.com API key\n",
    "\n",
    "1. Go to [you.com/platform](https://you.com/platform).\n",
    "2. Sign in or create an account.\n",
    "3. Generate an API key and copy it. **Keep it safe — you'll need it in the next step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Add the MCP server to Cursor\n",
    "\n",
    "Cursor reads MCP server configuration from a JSON file. You can configure it at the **project level** (only this project) or **globally** (all projects).\n",
    "\n",
    "#### Option A: Project-level (recommended for this course)\n",
    "\n",
    "Create or edit `.cursor/mcp.json` in your project root:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"ydc-server\": {\n",
    "      \"url\": \"https://api.you.com/mcp\",\n",
    "      \"headers\": {\n",
    "        \"Authorization\": \"Bearer <YOUR-YOU-COM-API-KEY>\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Replace `<YOUR-YOU-COM-API-KEY>` with your actual API key.\n",
    "\n",
    "#### Option B: Global\n",
    "\n",
    "Edit `~/.cursor/mcp.json` to make this available across all your Cursor projects.\n",
    "\n",
    "#### One-click install\n",
    "\n",
    "Alternatively, you can install directly from Cursor's MCP directory: visit the [You.com MCP page](https://docs.you.com/developer-resources/mcp-server) and click the **\"Install MCP Server\"** button for Cursor.\n",
    "\n",
    "> **Tip:** After saving `mcp.json`, restart Cursor or reload the window (`Cmd+Shift+P` → \"Reload Window\"). You should see the You.com tools available in the Agent chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Test your MCP connection\n",
    "\n",
    "Open Cursor's **Agent chat** (not the regular chat) and try a query that requires live web search:\n",
    "\n",
    "- *\"Search the web for the latest LLM benchmarks from 2025-2026.\"*\n",
    "- *\"What are the top open-source LLMs released in the last 6 months?\"*\n",
    "\n",
    "The agent should use the `you-search` tool to fetch live results. You'll see a tool-call indicator in the chat.\n",
    "\n",
    "> **Take a screenshot** of the agent using the You.com MCP tool in Cursor. Include it in your submission as `screenshots/mcp_you_com.png`.\n",
    "\n",
    "> **Troubleshooting:**\n",
    "> - If the tools don't appear, check that `mcp.json` is valid JSON (no trailing commas, correct quoting).\n",
    "> - Verify your API key is active at [you.com/platform](https://you.com/platform).\n",
    "> - Try restarting Cursor after editing the config.\n",
    "> - Go to Cursor Settings → Agents tab and turn off Cursor's built-in web search to avoid conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Alternative MCP servers\n",
    "\n",
    "You.com is the recommended MCP for this assignment, but you're welcome to configure additional servers. Here are some useful options:\n",
    "\n",
    "| MCP Server | What it provides | Get started |\n",
    "|------------|-----------------|-------------|\n",
    "| **You.com** (required) | Web search, news, content extraction | [you.com/platform](https://you.com/platform) |\n",
    "| **Brave Search** | Privacy-focused web search | [brave.com/search/api](https://brave.com/search/api/) |\n",
    "| **Tavily** | AI-optimized search for agents | [tavily.com](https://tavily.com/) |\n",
    "| **GitHub** | Code search, issues, PRs | [github.com/github/github-mcp-server](https://github.com/github/github-mcp-server) |\n",
    "| **Filesystem** | Read/write local files | Built into many MCP clients |\n",
    "\n",
    "Each follows the same pattern: get an API key, add a server entry to `mcp.json`, restart Cursor. The [MCP Registry](https://registry.modelcontextprotocol.io/) has a full catalog of available servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Bonus: Create an Agent Skill *(Optional, strongly encouraged)*\n",
    "\n",
    "An **Agent Skill** is a markdown document (`SKILL.md`) that gives an AI assistant domain knowledge. When a skill is loaded, the assistant knows how to use specific tools, follow procedures, and avoid common mistakes — without you having to explain everything in every prompt.\n",
    "\n",
    "Think of it as a **user manual for your agent's tools**, written so another AI can follow it.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "You've just built several tools (UC functions, Vector Search, MCP). But an AI assistant doesn't automatically know *when* to use each one, *how* to call them, or *what to watch out for*. A skill bridges that gap.\n",
    "\n",
    "### Create a skill\n",
    "\n",
    "Create a file called `SKILL.md` in your `assignment_3/` folder with the following structure:\n",
    "\n",
    "```markdown\n",
    "---\n",
    "name: ultrafeedback-expert\n",
    "description: >\n",
    "  Tools and knowledge for exploring the UltraFeedback LLM preference dataset.\n",
    "  Activate when: user asks about LLM preferences, model comparisons, or\n",
    "  instruction quality in the UltraFeedback dataset.\n",
    "---\n",
    "\n",
    "# UltraFeedback Expert\n",
    "\n",
    "## When to Use This Skill\n",
    "\n",
    "**Trigger patterns:**\n",
    "- \"UltraFeedback\" or \"preference data\" or \"chosen vs rejected\"\n",
    "- \"Which model is preferred\" or \"model comparison\"\n",
    "- \"Find similar instructions\" or \"semantic search\"\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "| Tool | Type | What it does |\n",
    "|------|------|--------------|\n",
    "| `main.default.lookup_source_info` | UC SQL | Returns row count and sample for a source |\n",
    "| `main.default.analyze_instruction` | UC Python | Analyzes instruction complexity |\n",
    "| `main.default.<your_function>` | UC SQL/Python | <your description> |\n",
    "| Vector Search index | Databricks VS | Semantic search over 1K instructions |\n",
    "| You.com MCP | External MCP | Live web search for current LLM info |\n",
    "\n",
    "## Procedures\n",
    "\n",
    "### Answering \"What sources are in the dataset?\"\n",
    "1. Call `lookup_source_info` for each known source.\n",
    "2. Summarize counts and sample instructions.\n",
    "\n",
    "### Finding similar instructions\n",
    "1. Query the Vector Search index with the user's text.\n",
    "2. Return the top 3-5 matches with their sources.\n",
    "\n",
    "## Gotchas\n",
    "- Vector Search endpoint must be running (recreate if deleted).\n",
    "- Column names with hyphens (e.g., `chosen-model`) need backtick escaping.\n",
    "```\n",
    "\n",
    "Fill in the details based on the actual tools you created. You can use this skill in Cursor by placing it in `~/.cursor/skills/` or referencing it in a project rule.\n",
    "\n",
    "**Docs:** [Agent Skills standard](https://github.com/xnano-ai/agentskills) · [Cursor Rules](https://cursor.com/docs/context/rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab complete\n",
    "\n",
    "### Required (Sections 1–7)\n",
    "- [ ] **Section 3:** Verified the UltraFeedback table exists.\n",
    "- [ ] **Section 4:** Created and tested the SQL function (`lookup_source_info`) and Python function (`analyze_instruction`).\n",
    "- [ ] **Section 4.3:** Created and tested your own UC function.\n",
    "- [ ] **Section 5:** Listed all registered UC functions.\n",
    "- [ ] **Section 6:** Created a Vector Search endpoint and index, queried it successfully, then **deleted both**.\n",
    "- [ ] **Section 7:** Configured the You.com MCP server in Cursor and tested it (screenshot taken).\n",
    "\n",
    "### Optional but strongly encouraged (Section 8)\n",
    "- [ ] **Section 8:** Created a `SKILL.md` documenting your tools.\n",
    "\n",
    "**Submit:** Your executed notebook (`.ipynb` with all outputs) and the completed `SUBMISSION_3.md`. Include screenshots in the `screenshots/` folder.\n",
    "\n",
    "*Next week you'll wire these tools into a working agent, register a prompt, and compare different LLMs.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}